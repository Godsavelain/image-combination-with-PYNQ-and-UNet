{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#import libs\n",
    "import time\n",
    "import cv2                                   \n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt  \n",
    "from pynq import Overlay\n",
    "import pynq.lib.dma\n",
    "from pynq import Xlnk\n",
    "import numpy as np\n",
    "from pynq import MMIO\n",
    "import random\n",
    "from pynq import allocate\n",
    "import numpy as np\n",
    "import socket, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define data containers\n",
    "pic_in_arr = allocate(shape=(600,800,3),dtype=np.uint8)\n",
    "bg_in_arr = allocate(shape=(600,800,3),dtype=np.uint8)\n",
    "mask_in_arr = allocate(shape=(600,800,3),dtype=np.uint8)\n",
    "out_arr = allocate(shape=(600,800,3),dtype=np.uint8)\n",
    "np_out = np.zeros((600,800,3), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ips\n",
    "overlay = Overlay(\"./design_1.bit\")\n",
    "ip = overlay.top_0\n",
    "#dma0 = overlay.axi_dma_0\n",
    "#dma1 = overlay.axi_dma_1\n",
    "#dma2 = overlay.axi_dma_2\n",
    "\n",
    "pic_dma = overlay.axi_dma_1\n",
    "mask_dma = overlay.axi_dma_0\n",
    "back_dma = overlay.axi_dma_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get background picture\n",
    "bg_img = cv2.imread(\"background2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #define internet transport interface\n",
    "# dest_ip = ('192.168.31.56', 13579)\n",
    "# UDP_server = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "# UDP_server.bind(('192.168.137.100', 23579))\n",
    "# example_image_path = './test.jpg'\n",
    "# example_save_path = './test_result.jpg'\n",
    "\n",
    "dest_ip = ('192.168.31.56', 13579)\n",
    "UDP_server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "UDP_server.connect(dest_ip)\n",
    "example_image_path = './test.jpg'\n",
    "# example_save_path = './test_result.jpg'\n",
    "example_save_path = './test_result.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def send_image(image, target_ip):\n",
    "#     data = cv2.imencode('.jpg', image)[1].tobytes()\n",
    "#     len_data = len(data)\n",
    "#     space = (len_data + 9999) // 10000\n",
    "#     UDP_server.sendto(space.to_bytes(4, 'big'), target_ip)\n",
    "#     for i in range(0, space):\n",
    "#         start_idx = i * 10000\n",
    "#         end_idx = min(len_data, (i+1) * 10000)\n",
    "#         UDP_server.sendto(data[start_idx: end_idx], target_ip)\n",
    "#     return 'Send Image OK'\n",
    "\n",
    "def send_image(image):\n",
    "    data = cv2.imencode('.jpg', image)[1].tobytes()\n",
    "    len_data = len(data)\n",
    "    space = len_data\n",
    "    UDP_server.sendall(space.to_bytes(16, 'big'))\n",
    "    UDP_server.sendall(data)\n",
    "    return 'Send Image  OK'\n",
    "\n",
    "# def recv_image(image_path):\n",
    "#     space, addr = UDP_server.recvfrom(10000)\n",
    "#     space = int.from_bytes(space, 'big')\n",
    "#     with open(image_path, 'wb') as f:\n",
    "#         for i in range(space):\n",
    "#             data, addr_now = UDP_server.recvfrom(10000)\n",
    "#             assert addr == addr_now\n",
    "#             f.write(data)\n",
    "#     return 'recv Image OK'\n",
    "def recv_image(image_path):\n",
    "    space = UDP_server.recv(16)\n",
    "    space = int.from_bytes(space, 'big')\n",
    "    #print('space {}'.format(space))\n",
    "    with open(image_path, 'wb') as f:\n",
    "        while space > 0:\n",
    "            data = UDP_server.recv(1024)\n",
    "            #print('data len {}'.format(len(data)))\n",
    "            space -= len(data)\n",
    "            f.write(data)\n",
    "    return 'Recv Image {} OK'.format(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "readcap = cv2.VideoCapture(\"testread.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap2 = cv2.VideoCapture(1) \n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('testwrite.mp4',fourcc, 10.0, (800,600),True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, np_frame = readcap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    np_frame = cv2.resize(np_frame,(800,600))\n",
    "    send_image(np_frame)\n",
    "    recv_image(example_save_path)\n",
    "    mask_img = cv2.imread(\"test_result.jpg\")\n",
    "    np.copyto(pic_in_arr,np_frame)\n",
    "    np.copyto(bg_in_arr,bg_img)\n",
    "    np.copyto(mask_in_arr,mask_img)\n",
    "    #dma\n",
    "    pic_dma.sendchannel.transfer(pic_in_arr)\n",
    "    mask_dma.sendchannel.transfer(mask_in_arr)\n",
    "    back_dma.sendchannel.transfer(bg_in_arr)\n",
    "    mask_dma.recvchannel.transfer(out_arr)\n",
    "    ip.write(0x00, 0x1)\n",
    "    isready = ip.read(0x00)\n",
    "    while (isready == 1):\n",
    "        isready = ip.read(0x00)\n",
    "    pic_dma.sendchannel.wait()\n",
    "    mask_dma.sendchannel.wait()\n",
    "    back_dma.sendchannel.wait()\n",
    "    mask_dma.recvchannel.wait()\n",
    "    np.copyto(np_out,out_arr)\n",
    "    out.write(np_out)\n",
    "    print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ips\n",
    "overlay = Overlay(\"./design_1.bit\")\n",
    "ip = overlay.top_0\n",
    "#dma0 = overlay.axi_dma_0\n",
    "#dma1 = overlay.axi_dma_1\n",
    "#dma2 = overlay.axi_dma_2\n",
    "\n",
    "pic_dma = overlay.axi_dma_1\n",
    "mask_dma = overlay.axi_dma_0\n",
    "back_dma = overlay.axi_dma_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap2.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "readcap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pynq import Overlay,allocate\n",
    "import pynq.lib.video\n",
    "from pynq.lib.video.common import PixelFormat,VideoMode\n",
    "\n",
    "framemode = VideoMode(800,600,32)\n",
    "vdma=overlay.axi_vdma_0\n",
    "vdma.writechannel.mode=framemode\n",
    "vdma.writechannel.start()\n",
    "vdma.writechannel.parked\n",
    "\n",
    "#buf=np.zeros((800,600,3),dtype=np.int8)\n",
    "buf=vdma.writechannel.newframe()\n",
    "#buf=np.zeros((600,800,3),dtype=np.int32)\n",
    "\n",
    "#buf[:,:,:]=np.zeros((600,800,4),dtype=np.uint8)\n",
    "\n",
    "\n",
    "vdma.writechannel.setframe(buf)\n",
    "tpg = overlay.v_tpg_0\n",
    "tpg.write(0x10,600)\n",
    "tpg.write(0x18,800)\n",
    "tpg.write(0x40,0)\n",
    "tpg.write(0x20,0x9)\n",
    "tpg.write(0x0,0x81)\n",
    "\n",
    "bin(tpg.read(0x0))\n",
    "tpg.read(0x4)\n",
    "tpg.read(0xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix = overlay.v_mix_0\n",
    "mix.write(0x4,0)\n",
    "mix.write(0x10,800)\n",
    "mix.write(0x18,600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix.write(0x100,0)\n",
    "mix.write(0x108,0)\n",
    "mix.write(0x110,0)\n",
    "mix.write(0x118,800)\n",
    "mix.write(0x120,48)\n",
    "mix.write(0x128,600)\n",
    "mix.write(0x130,0)\n",
    "\n",
    "mix.write(0x200,255)\n",
    "mix.write(0x208,0)\n",
    "mix.write(0x210,0) \n",
    "mix.write(0x218,800)\n",
    "mix.write(0x220,48)\n",
    "mix.write(0x228,600)\n",
    "mix.write(0x230,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix.write(0x40,0b11)\n",
    "mix.write(0x0,0x81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "readcap2 = cv2.VideoCapture(\"testwrite.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, np_frame = readcap2.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    buf[:,:,0]=np_frame[:,:,1]\n",
    "    buf[:,:,1]=np_frame[:,:,0]\n",
    "    buf[:,:,2]=np_frame[:,:,2]\n",
    "    buf[:,:,3]=0xff\n",
    "    time.sleep(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "readcap2.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
